---
title: "ld_simulations"
author: "Marcus Tutert"
date: "21/02/2021"
output: html_document
---
This notebook will be used to perform all the LD simulations for Chapter 2 of my thesis
Any associated scripts/functions called will (hopefully) also be in this directory
Setting up python chunks and r chunks is done in the chunk header, and python is called in r as py$object
```{r setup, include=FALSE}
#Source all the scripts I need here
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
source("~/Desktop/Oxford_Dphil/InferLD/R/Weights_LD_Inference.R")
```

```{python}
import msprime
import allel; print('scikit-allel', allel.__version__)
import numpy as np
```


First thing we want to show is the stochastic process of LD
Going to show this from a simulated context (w in Gils code)
Here is a WF model without recombination to illustrate that point
```{r, echo = FALSE}

#To simulate drift in LD metrics

#N    = Pop size
#f0   = Initial haplotype frequencies (00, 10, 01, 11)
#gens = No. generations
#r    = recombination rate

simulate.pop<-function(N=1000, f0=c(0.25, 0.25, 0.25, 0.25), gens=100, r=0.001, show.plot=TRUE) {

	f0<-f0/sum(f0);				               #Normalise freqs
	type0<-sample(1:4, N, rep=T, p=f0);	 #Sample initial population with given frequencies
	pop0<-array(0, c(N, 2));             #Store array of dimension pop size by 2
	#Pop0 looks at the presence of a mutation at either site 1 or 2
	pop0[(type0==2) | (type0==4), 1] = 1 #10 or 11 haplotype
	pop0[(type0==3) | (type0==4), 2] = 1 #01 or 11 haplotype
	#This means that there will be LD(?) in these populations

	#Initialise results array
	op<-array(0, c(gens, 5));                         #Generate results array
	colnames(op)<-c("Gen", "F1", "F2", "D12", "rAB"); #Store results (Gen, pi_pop_1, pi_pop_2,D,r)
	op[1,]<-c(1, mean(pop0[,1]), mean(pop0[,2]), cov(pop0[,1], pop0[,2]), cor(pop0[,1], pop0[,2]));

	#Run simulation
	for (gen in 1:gens) {
		par1<-sample(N, N, replace=T); #Sample parent 1
		pop1<-pop0[par1,];             #Extract parents in population
		w.rec<-which(runif(N)<r);			 #Choose who to recombine
		if (length(w.rec)>0) {
			par2<-sample(N, length(w.rec));
			pop1[w.rec,2]<-pop0[par2,2];
		}
		pop0<-pop1;
		op[gen,]<-c(gen, mean(pop0[,1]), mean(pop0[,2]), cov(pop0[,1], pop0[,2]), cor(pop0[,1], pop0[,2]));
		if (min(op[gen,2:3])<1e-6) {
			break();
			op<-op[1:gen,];
		}
	}

	if (show.plot) {
		par(mfrow=c(1,1));
		plot(op[,1], op[,2], type="l", col="blue", xlab="Generation", ylab="Population Genetic Statistics", ylim=c(0,1));
		lines(op[,1], op[,3], type="l", col="orange");
		lines(op[,1], abs(op[,5]), type="l", col="black", lwd=2)
	}

	return(op);
}

#Single example
tmp<-simulate.pop(N=500, f0=c(0.25,0.25,0.25,0.25), gens=100, r=1e-100)
legend( "topleft", c("LD rAB", "Allele Frequency A", "Allele Frequency B"))
mtext("Wright Fischer Model without Recombination", side = 3, line = -3, outer = TRUE)

```
Now we plot WF with some recombination

```{r, echo = FALSE, figures-side, fig.show="hold", out.width="50%"}
#WF w recombination
par(mfrow = c(2, 2)) # Create a 2 x 2 plotting matrix
recomb_params = c(0.5,0.01,0.001, 0.001)
for (i in 1:length(recomb_params)) {
  tmp<-simulate.pop(N=500, f0=c(0.25,0.25,0.25,0.25), gens=100, r=recomb_params[i])
 title(sprintf("%s Recombination", recomb_params[i]))
}
mtext("Wright Fischer Model with Recombination", side = 3, line = -5, outer = TRUE)
legend( "topleft", c("LD rAB", "Allele Frequency A", "Allele Frequency B"))
```

Now let's do something with showing the stoachastic nature of the genealogy
```{r, echo = FALSE}
#Multiple examples with same starting point
par(mfrow = c(2, 2)) # Create a 2 x 2 plotting matrix
recomb_params = c(0.9,0.1,0.01, 0.0001)
for (j in 1:length(recomb_params)) {
  n.sim<-100;
N.sim<-1000;
gens.sim<-100;
f0.sim<-c(1,1,1,1);
r.sim<-0.001;
plot(c(0,0), xlim=c(0,gens.sim), ylim=c(-1,1), xlab="Generation", ylab="rAB", type="n");
for (i in 1:n.sim) {
	tmp<-simulate.pop(N=N.sim, f0=f0.sim, gens=gens.sim, r=recomb_params[j], show.plot=F);
	lines(tmp[,1], tmp[,5], col=hsv(0,0,0,alpha=0.2));
  }
}
mtext("Stochastic Genealogical Formation of LD Across Recombination Rates", side = 3, line = -3, outer = TRUE)
```

## Coalescent Simulations
Now we move to coalescent simulations using msprime. First we begin creating a msprime simulation where we just draw a single two groups of samples from the same underlying population. There will be a recombination hotspot in middle (human level?) and no recombination elsewhere
```{python}
import msprime
import allel; print('scikit-allel', allel.__version__)
import numpy as np
#Draw 10000 people
tree = msprime.simulate(sample_size=1000, Ne=1000, length=1e4, recombination_rate=1e-8, mutation_rate=1e-6)
#Convert to  haplotype format
haps = np.transpose(np.asarray(allel.HaplotypeArray(tree.genotype_matrix())))
```

```{r}
#In R, split the population into two and compare the LD
dim(py$haps)
pop_1 = py$haps[1:(nrow(py$haps)/2),]
pop_2 = py$haps[((nrow(py$haps)/2)+1):nrow(py$haps),]
#Get the LD w my measurem
plot(LD_Matrix(pop_1),LD_Matrix(pop_2))
```

Now lets do this across a bunch of different runs and see what the density of the correlation is
```{python}
#Draw 10000 people
tree = msprime.simulate(sample_size=100000, Ne=1000, length=1e4, recombination_rate=1e-8, mutation_rate=1e-6)
#Convert to  haplotype format
haps = np.transpose(np.asarray(allel.HaplotypeArray(tree.genotype_matrix())))
```
```{r}
#In R, split the population into two and compare the LD
dim(py$haps)
pops_split =  seq(1,100000,500)
r2 = c()
for (i in 1:5) {
  print(i)
  pop_1 = py$haps[pops_split[i]:pops_split[i+1],]
  pop_2 = py$haps[pops_split[i+1]:pops_split[i+2],]
  #Compare the LD
  r2[i] = summary(lm(c(LD_Matrix(pop_1))~c(LD_Matrix(pop_2))))$r.squared
}
hist(r2, main = "r2 of LD across msprime draws with similiar levels of LD")
```
However this data includes a lot of non-segregating variants!
```{r}
#In R, split the population into two and compare the LD
dim(py$haps)
pops_split =  seq(1,100000,500)
r2 = c()
for (i in 1:5) {
  print(i)
  pop_1 = py$haps[pops_split[i]:pops_split[i+1],]
  pop_2 = py$haps[pops_split[i+1]:pops_split[i+2],]
  #Compare the LD
  r2[i] = summary(lm(c(LD_Matrix(pop_1))~c(LD_Matrix(pop_2))))$r.squared
}
hist(r2, main = "r2 of LD across msprime draws with similiar levels of LD")
```

```{r}
dim(py$haps)
x = py$haps
r2 = c()
pops_split =  seq(1,100000,500)
for (i in 1:3) {
  segregating_index_pop_1 = which(colMeans(x[(pops_split[i]:(pops_split[i+1]-1)),]) > 0)
  low_freq_pop_1          = 
  segregating_index_pop_2 = which(colMeans(x[pops_split[i+1]:(pops_split[i+2]-1),]) > 0)
  low_freq_pop_2          = 
  intersect_segregating <- intersect(segregating_index_pop_1,segregating_index_pop_2)
  pop_1 = x[pops_split[i]:(pops_split[i+1]-1), intersect_segregating]
  pop_2 = x[pops_split[i+1]:(pops_split[i+2]-1), intersect_segregating]
  r2[i] = summary(lm(c(LD_Matrix(pop_1))~c(LD_Matrix(pop_2))))$r.squared
}

```

# Conditional AFs
Now we can choose to look at a single value in one population conditional on the value in some other population
```{python}
tree = msprime.simulate(sample_size=2000, Ne=1000, length=1e4, recombination_rate=1e-8, mutation_rate=1e-4)
haps = np.transpose(np.asarray(allel.HaplotypeArray(tree.genotype_matrix())))
np.shape(haps)
```


# Population Split

Ok, now we can do the fun stuff and start introducing some population structure into the data

```{r}

```

# Summary Statistic Imputation
What we want to do is:
1)Simulate a GWAS population 
2)Generate LD from either the same or a different population
3)Do this many times to get a distribution
4)
```{python}
map_positions = [i*1 for i in range(0, 3)]
map_rates = [0,1e-1,0]
my_map = msprime.RecombinationMap(map_positions, map_rates)
tree = msprime.simulate(sample_size=10000, Ne=1000,recombination_map = my_map, mutation_rate=5e-2)
haps = np.transpose(np.asarray(allel.HaplotypeArray(tree.genotype_matrix())))
np.shape(haps)
```
```{r}
#Generate GWAS sumstats under the null model
source("~/Desktop/Oxford_Dphil/InferLD_Validations/coalescent_simulations/helper_functions.R")
x = msprime_gwas_sumstats(gwas_haplotypes = py$haps[1:500,],reference_haplotypes = py$haps[501:1000,])
sumstats = x[[3]] #Extract out the sumstats
#Choose a subset of the sumstats to be imputed vs genotyped
nsnps        = nrow(sumstats)
n_imputed    = 600
imputed_snps = sort(sample(1:nsnps,n_imputed))
#Run the sumstat imputation
#Write out the GWAS sumstats & 
res_1 = sumstat_impute(typed_snps = setdiff(1:nsnps,imputed_snps),
               untyped_snps_index = imputed_snps, 
               genotyped_sumstats = sumstats[-imputed_snps,], 
               imputed_sumstats = sumstats[imputed_snps,], 
               LD = LD_Matrix(x[[1]]))
#Now do this across different subsets of the 

```



